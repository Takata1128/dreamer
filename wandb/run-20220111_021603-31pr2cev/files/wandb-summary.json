{"train_rewards": 0, "action_ent": 1.0900425513585408, "train_steps": 8054, "_runtime": 175, "_timestamp": 1641867538, "_step": 8054, "model_loss": 372.40101928710936, "kl_loss": 0.00783891836181283, "reward_loss": 0.9380571484565735, "obs_loss": 369.08421630859374, "value_loss": 0.888822340965271, "actor_loss": 0.21750905215740204, "prior_entropy": 0.09821822345256806, "posterior_entropy": 0.04681435003876686, "pcont_loss": 0.47559280395507814, "mean_targ": 3.0742749214172362, "min_targ": 3.0447947502136232, "max_targ": 3.10162672996521, "std_targ": 0.01944693075492978}