{"train_rewards": 0, "action_ent": 0.014653905294835567, "train_steps": 13996, "_runtime": 251, "_timestamp": 1641862727, "_step": 13996, "model_loss": 372.2798583984375, "kl_loss": 0.002573148999363184, "reward_loss": 0.9316735863685608, "obs_loss": 368.90496826171875, "value_loss": 0.8837920308113099, "actor_loss": 0.002927498263306916, "prior_entropy": 0.06574404239654541, "posterior_entropy": 0.04372266307473183, "pcont_loss": 0.488592141866684, "mean_targ": 3.0654850006103516, "min_targ": 3.0375558376312255, "max_targ": 3.0820573806762694, "std_targ": 0.015819645021110773}