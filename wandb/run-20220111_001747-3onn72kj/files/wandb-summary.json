{"train_rewards": 0, "action_ent": 0.0005745593031557897, "train_steps": 53498, "_runtime": 969, "_timestamp": 1641861236, "_step": 53498, "model_loss": 371.83099365234375, "kl_loss": 0.00013992976455483585, "reward_loss": 0.9212889909744263, "obs_loss": 368.41212158203126, "value_loss": 0.8853409647941589, "actor_loss": -6.073355598346097e-06, "prior_entropy": 0.004367580357939005, "posterior_entropy": 0.002887115441262722, "pcont_loss": 0.49951211810112, "mean_targ": 9.22304916381836, "min_targ": 9.005416870117188, "max_targ": 9.37714500427246, "std_targ": 0.12175009697675705}