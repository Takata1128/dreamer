{"train_rewards": 7, "action_ent": 0.0004326405598695797, "_runtime": 95875, "_timestamp": 1641849126, "_step": 4999928, "model_loss": 368.6459106445312, "kl_loss": 0.8032699227333069, "reward_loss": 0.9193061351776123, "obs_loss": 367.59320678710935, "value_loss": 0.9498004198074341, "actor_loss": -0.00708915435243398, "prior_entropy": 5.637246131896973, "posterior_entropy": 4.855096912384033, "pcont_loss": 0.01061522364616394, "mean_targ": 7.924241256713867, "min_targ": 7.890126895904541, "max_targ": 7.940099716186523, "std_targ": 0.016605643928050993, "_wandb": {"runtime": 95877}}