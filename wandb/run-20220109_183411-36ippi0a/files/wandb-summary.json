{"train_rewards": 6, "action_ent": 0.0009205501581131477, "_runtime": 67406, "_timestamp": 1641820657, "_step": 3513914, "model_loss": 368.66181640625, "kl_loss": 0.8301250219345093, "reward_loss": 0.9194119095802307, "obs_loss": 367.5991516113281, "value_loss": 0.9335974931716919, "actor_loss": -0.0012329168850556016, "prior_entropy": 5.200735092163086, "posterior_entropy": 4.3963157653808596, "pcont_loss": 0.01204723147675395, "mean_targ": 7.572037220001221, "min_targ": 7.542642211914062, "max_targ": 7.587390327453614, "std_targ": 0.015690157748758794}