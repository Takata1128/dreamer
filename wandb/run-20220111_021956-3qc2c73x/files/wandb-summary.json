{"train_rewards": 0, "action_ent": 6.863224174085059e-32, "train_steps": 433744, "_runtime": 8131, "_timestamp": 1641875727, "_step": 433744, "model_loss": 371.61167602539064, "kl_loss": 6.440807510443847e-07, "reward_loss": 0.9204614043235779, "obs_loss": 368.17601318359374, "value_loss": 0.8891482830047608, "actor_loss": -2.264350980848515e-23, "prior_entropy": 0.0003895481582731009, "posterior_entropy": 0.0003265288018155843, "pcont_loss": 0.5030405282974243, "mean_targ": 5.081478404998779, "min_targ": 4.906037712097168, "max_targ": 5.191982555389404, "std_targ": 0.09127060323953629}