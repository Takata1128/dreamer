{"train_rewards": 0, "action_ent": 0.0059432329920430975, "train_steps": 15794, "_runtime": 307, "_timestamp": 1641863808, "_step": 15794, "model_loss": 372.3607971191406, "kl_loss": 0.003412465984001756, "reward_loss": 0.9341691374778748, "obs_loss": 368.91923828125, "value_loss": 0.8846989750862122, "actor_loss": -0.0010096793703269213, "prior_entropy": 0.6764888644218445, "posterior_entropy": 0.6722316861152648, "pcont_loss": 0.5014092564582825, "mean_targ": 7.590201377868652, "min_targ": 7.546062755584717, "max_targ": 7.606341457366943, "std_targ": 0.019482025876641273}