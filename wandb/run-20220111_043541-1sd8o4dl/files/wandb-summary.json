{"train_rewards": 3, "action_ent": 0.01281698849010063, "train_steps": 1362778, "_runtime": 25867, "_timestamp": 1641901608, "_step": 1362778, "model_loss": 368.71961669921876, "kl_loss": 0.464190673828125, "reward_loss": 0.9192104458808898, "obs_loss": 367.5921142578125, "value_loss": 0.8656738519668579, "actor_loss": -0.000377876462880522, "prior_entropy": 2.9808161735534666, "posterior_entropy": 2.4870718002319334, "pcont_loss": 0.032375065609812737, "mean_targ": 2.8079405307769774, "min_targ": 2.604056167602539, "max_targ": 2.9151730060577394, "std_targ": 0.11338499188423157}