{"train_rewards": 1, "action_ent": 0.0009661445128869322, "train_steps": 1999986, "_runtime": 37937, "_timestamp": 1641913678, "_step": 1999986, "model_loss": 368.7050048828125, "kl_loss": 0.4954472780227661, "reward_loss": 0.9192436099052429, "obs_loss": 367.5926513671875, "value_loss": 0.8613431453704834, "actor_loss": -0.0011752025573514401, "prior_entropy": 3.1482792854309083, "posterior_entropy": 2.654514503479004, "pcont_loss": 0.028711744025349616, "mean_targ": 2.8847726345062257, "min_targ": 2.67329363822937, "max_targ": 3.0003007888793944, "std_targ": 0.11912946552038192, "_wandb": {"runtime": 37938}}