{"train_rewards": 0, "action_ent": 2.8761409241043266e-15, "train_steps": 115292, "_runtime": 2221, "_timestamp": 1641866077, "_step": 115292, "model_loss": 371.7270874023437, "kl_loss": 7.086914956744295e-06, "reward_loss": 0.9202550053596497, "obs_loss": 368.2177795410156, "value_loss": 0.8862406849861145, "actor_loss": -9.552066567393762e-16, "prior_entropy": 0.013027930073440075, "posterior_entropy": 0.012918568029999734, "pcont_loss": 0.5178099393844604, "mean_targ": -0.5366762518882752, "min_targ": -0.8726652503013611, "max_targ": -0.2984872817993164, "std_targ": 0.20702305138111116}