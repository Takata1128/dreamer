{"train_rewards": 0, "action_ent": 0.09983156993985176, "train_steps": 9846, "_runtime": 184, "_timestamp": 1641866524, "_step": 9846, "model_loss": 372.36602783203125, "kl_loss": 0.002055006963200867, "reward_loss": 0.9361930370330811, "obs_loss": 369.0437377929687, "value_loss": 0.8842666506767273, "actor_loss": 0.0374121118336916, "prior_entropy": 0.907037878036499, "posterior_entropy": 0.8904364824295044, "pcont_loss": 0.47717644572257994, "mean_targ": 5.036666393280029, "min_targ": 5.003394412994385, "max_targ": 5.059291553497315, "std_targ": 0.020027042366564274}